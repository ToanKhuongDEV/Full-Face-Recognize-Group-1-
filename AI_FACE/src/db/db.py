from dotenv import load_dotenv
import os
import json
import numpy as np
from typing import List, Tuple, Optional

from sqlalchemy import (create_engine, MetaData, Table,
    Column,
    Integer,
    String,
    JSON,
    ForeignKey,
    DateTime,
    select,
    func,
    text
)
from sqlalchemy.exc import SQLAlchemyError
from uuid import uuid4
from datetime import datetime

# Load bi·∫øn m√¥i tr∆∞·ªùng
load_dotenv()

# --- C·∫§U H√åNH K·∫æT N·ªêI DB (ƒê√£ t·ªëi ∆∞u cho .env c·ªßa b·∫°n) ---
DATABASE_URI = os.getenv("DATABASE_URI")

# N·∫øu ch∆∞a c√≥ bi·∫øn g·ªôp, t·ª± ƒë·ªông gh√©p t·ª´ c√°c bi·∫øn l·∫ª
if not DATABASE_URI:
    host = os.getenv("DB_HOST", "localhost")
    port = os.getenv("DB_PORT", "3306")
    user = os.getenv("DB_USER", "root")
    password = os.getenv("DB_PASSWORD", "")
    dbname = os.getenv("DB_NAME", "face_attendance")
    DATABASE_URI = f"mysql+pymysql://{user}:{password}@{host}:{port}/{dbname}?charset=utf8mb4"

# C·∫•u h√¨nh Engine
engine_kwargs = {
    "future": True,
    "pool_pre_ping": True, # T·ª± ƒë·ªông k·∫øt n·ªëi l·∫°i n·∫øu r·ªõt m·∫°ng
    "echo": False,
}

# C·∫•u h√¨nh SSL (Ch·ªâ b·∫≠t n·∫øu DB_SSL_MODE kh√°c DISABLED)
DB_SSL_MODE = os.getenv("DB_SSL_MODE", "DISABLED")
if DB_SSL_MODE != "DISABLED":
    engine_kwargs["connect_args"] = {
        "ssl_verify_cert": True,
        "ssl_verify_identity": True,
    }

print(f"üîå K·∫øt n·ªëi DB: {DATABASE_URI.split('@')[-1]}") # Log t√™n DB (che m·∫≠t kh·∫©u)

try:
    engine = create_engine(DATABASE_URI, **engine_kwargs)
    metadata = MetaData()
except Exception as e:
    print(f"‚ùå L·ªói kh·ªüi t·∫°o Engine: {e}")
    raise

# Cache trong RAM
_ENC_CACHE = None

# --- ƒê·ªäNH NGHƒ®A B·∫¢NG ---

# B·∫£ng nh√¢n vi√™n
employees_table = Table(
    "employees",
    metadata,
    Column("id", String(255), primary_key=True),
    Column("full_name", String(255), nullable=False),
    Column("employee_code", Integer, nullable=False),
    Column("avatar", String(255), nullable=True),
)

# B·∫£ng d·ªØ li·ªáu khu√¥n m·∫∑t
face_data_table = Table(
    "face_data",
    metadata,
    Column("id", String(255), primary_key=True),
    Column("created_at", DateTime(timezone=True), server_default=func.now()),
    Column("encoding", JSON, nullable=False),
    Column("employee_id", String(255), ForeignKey("employees.id"), nullable=False),
)

def get_connection():
    return engine.connect()

def init_db():
    metadata.create_all(engine)

# --- C√ÅC H√ÄM T∆Ø∆†NG T√ÅC ---

def load_known_faces() -> Tuple[List[np.ndarray], List[str], List[str]]:
    """
    Load to√†n b·ªô d·ªØ li·ªáu khu√¥n m·∫∑t v√† t√™n nh√¢n vi√™n l√™n RAM.
    """
    global _ENC_CACHE
    if _ENC_CACHE is not None:
        return _ENC_CACHE

    encodings = []
    names = []
    ids = []

    print("üîÑ ƒêang t·∫£i d·ªØ li·ªáu khu√¥n m·∫∑t t·ª´ Database...")
    with get_connection() as conn:
        stmt = select(
            face_data_table.c.encoding,
            employees_table.c.full_name,
            employees_table.c.id
        ).select_from(
            face_data_table.join(employees_table, face_data_table.c.employee_id == employees_table.c.id)
        )
        
        try:
            results = conn.execute(stmt).fetchall()
            if not results:
                print("‚ö†Ô∏è Database ch∆∞a c√≥ d·ªØ li·ªáu khu√¥n m·∫∑t.")
                return [], [], []

            for row in results:
                vec_data = row.encoding
                try:
                    # Chuy·ªÉn ƒë·ªïi JSON list sang numpy array
                    if isinstance(vec_data, str):
                        vec_data = json.loads(vec_data)
                    
                    arr = np.array(vec_data, dtype=np.float64)
                    
                    encodings.append(arr)
                    names.append(row.full_name)
                    ids.append(row.id)
                except Exception as e:
                    print(f"‚ùå L·ªói parse vector ID {row.id}: {e}")
                    continue
            
            print(f"‚úÖ ƒê√£ t·∫£i th√†nh c√¥ng {len(encodings)} khu√¥n m·∫∑t.")

        except SQLAlchemyError as e:
            print(f"‚ùå L·ªói Database khi t·∫£i: {e}")
            return [], [], []

    _ENC_CACHE = (encodings, names, ids)
    return encodings, names, ids

def add_face_encoding(employee_id: str, encoding: List[float]) -> bool:
    """Th√™m vector khu√¥n m·∫∑t m·ªõi."""
    new_id = str(uuid4())
    
    if isinstance(encoding, np.ndarray):
        encoding_list = encoding.tolist()
    else:
        encoding_list = encoding

    stmt = face_data_table.insert().values(
        id=new_id,
        created_at=datetime.now(), # ƒê√£ s·ª≠a utcnow -> now
        encoding=encoding_list,
        employee_id=employee_id
    )

    with get_connection() as conn:
        try:
            conn.execute(stmt)
            conn.commit()
            
            global _ENC_CACHE
            _ENC_CACHE = None
            print(f"‚úÖ ƒê√£ l∆∞u vector m·ªõi cho nh√¢n vi√™n ID: {employee_id}")
            return True
        except SQLAlchemyError as e:
            print(f"‚ùå L·ªói l∆∞u d·ªØ li·ªáu: {e}")
            conn.rollback()
            return False

def get_employee_by_id(employee_id: str):
    """L·∫•y th√¥ng tin nh√¢n vi√™n."""
    with get_connection() as conn:
        stmt = select(employees_table).where(employees_table.c.id == employee_id)
        row = conn.execute(stmt).first()
        return row

def delete_face_data(employee_id: str) -> int:
    """X√≥a d·ªØ li·ªáu khu√¥n m·∫∑t c·ªßa nh√¢n vi√™n."""
    with get_connection() as conn:
        try:
            stmt = face_data_table.delete().where(face_data_table.c.employee_id == employee_id)
            result = conn.execute(stmt)
            conn.commit()
            
            global _ENC_CACHE
            _ENC_CACHE = None
            return result.rowcount
        except SQLAlchemyError as e:
            conn.rollback()
            raise e

def refresh_cache():
    global _ENC_CACHE
    _ENC_CACHE = None
    load_known_faces()